{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Distributional semantics\n",
    "\n",
    "This is due on **11/27 (11:55pm)**, submitted electronically. \n",
    "\n",
    "## How to do this problem set\n",
    "\n",
    "Most of these questions require writing Python code and computing results, and the rest of them have textual answers.  Write all the textual answers in this document, show the output of your experiment in this document, and implement the functions in the `distsim.py`. Once you are finished, you will upload this `.ipynb` file and `distsim.py` to Moodle.\n",
    "\n",
    "* When creating your final version of the problem set to hand in, please do a fresh restart and execute every cell in order.  Then you'll be sure it's actually right.  Make sure to press \"Save\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Name:**\n",
    "\n",
    "**List collaborators, and how you collaborated, here:** (see our [grading and policies page](http://people.cs.umass.edu/~brenocon/inlp2016/grading.html) for details on our collaboration policy).\n",
    "\n",
    "* _Aditya Shastry_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, where $i$ indexes over the context types, cosine similarity is defined as follows. $x$ and $y$ are both vectors of context counts (each for a different word), where $x_i$ is the count of context $i$.\n",
    "\n",
    "$$cossim(x,y) = \\frac{ \\sum_i x_i y_i }{ \\sqrt{\\sum_i x_i^2} \\sqrt{\\sum_i y_i^2} }$$\n",
    "\n",
    "The nice thing about cosine similarity is that it is normalized: no matter what the input vectors are, the output is between 0 and 1. One way to think of this is that cosine similarity is just, um, the cosine function, which has this property (for non-negative $x$ and $y$). Another way to think of it is, to work through the situations of maximum and minimum similarity between two context vectors, starting from the definition above.\n",
    "\n",
    "Note: a good way to understand the cosine similarity function is that the numerator cares about whether the $x$ and $y$ vectors are correlated. If $x$ and $y$ tend to have high values for the same contexts, the numerator tends to be big. The denominator can be thought of as a normalization factor: if all the values of $x$ are really large, for example, dividing by the square root of their sum-of-squares prevents the whole thing from getting arbitrarily large. In fact, dividing by both these things (aka their norms) means the whole thing can’t go higher than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "See the file `nytcounts.university_cat_dog`, which contains context count vectors for three words: “dog”, “cat”, and “university”. These are immediate left and right contexts from a New York Times corpus. You can open the file in a text editor since it’s quite small.\n",
    "\n",
    "Please complete `cossim_sparse(v1,v2)` in `distsim.py` to compute and display the cosine similarities between each pair of these words. Briefly comment on whether the relative simlarities make sense.\n",
    "\n",
    "Note that we’ve provided very simple code that tests the context count vectors from the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.university_cat_dog has contexts for 3 words\n",
      "Cosine similarity between cat and dog 0.966891672715\n",
      "Cosine similarity between cat and university 0.660442421144\n",
      "Cosine similarity between university and dog 0.659230248969\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.university_cat_dog\")\n",
    "print \"Cosine similarity between cat and dog\" ,distsim.cossim_sparse(word_to_ccdict['cat'],word_to_ccdict['dog'])\n",
    "print \"Cosine similarity between cat and university\" ,distsim.cossim_sparse(word_to_ccdict['cat'],word_to_ccdict['university'])\n",
    "print \"Cosine similarity between university and dog\" ,distsim.cossim_sparse(word_to_ccdict['university'],word_to_ccdict['dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your response here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (15 points)\n",
    "\n",
    "Implement `show_nearest()`. \n",
    "Given a dictionary of word-context vectors, the context vector of a particular query word `w`, the words you want to exclude in the responses (It should be the query word `w` in this question), and the similarity metric you want to use (It should be the `cossim_sparse` function you just implemented), `show_nearest()` finds the 20 words most-similar to `w`. For each, display the other word, and its similarity to the query word `w`.\n",
    "\n",
    "To make sure it’s working, feel free to use the small `nytcounts.university_cat_dog` database as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.university_cat_dog has contexts for 3 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cat', 'university']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distsim\n",
    "reload(distsim)\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.university_cat_dog\")\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['dog'], set(['dog']), distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Explore similarities in `nytcounts.4k`, which contains context counts for about 4000 words in a sample of New York Times. The news data was lowercased and URLs were removed. The context counts are for the 2000 most common words in twitter, as well as the most common 2000 words in the New York Times. (But all context counts are from New York Times.) The context counts only contain contexts that appeared for more than one word. The file `vocab` contains the list of all terms in this data, along with their total frequency.\n",
    "Choose **six** words. For each, show the output of `show_nearest()` and comment on whether the output makes sense. Comment on whether this approach to distributional similarity makes more or less sense for certain terms.\n",
    "Four of your words should be:\n",
    "\n",
    " * a name (for example: person, organization, or location)\n",
    " * a common noun\n",
    " * an adjective\n",
    " * a verb\n",
    "\n",
    "You may also want to try exploring further words that are returned from a most-similar list from one of these. You can think of this as traversing the similarity graph among words.\n",
    "\n",
    "*Implementation note:* \n",
    "On my laptop it takes several hundred MB of memory to load it into memory from the `load_contexts()` function. If you don’t have enough memory available, your computer will get very slow because the OS will start swapping. If you have to use a machine without that much memory available, you can instead implement in a streaming approach by using the `stream_contexts()` generator function to access the data; this lets you iterate through the data from disk, one vector at a time, without putting everything into memory. You can see its use in the loading function. (You could also alternatively use a key-value or other type of database, but that’s too much work for this assignment.)\n",
    "\n",
    "*Extra note:* \n",
    "You don’t need this, but for reference, our preprocessing scripts we used to create the context data are in the `preproc/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.4k has contexts for 3648 words\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.4k\")\n",
    "###Provide your answer below; perhaps in another cell so you don't have to reload the data each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peter',\n",
       " 'joseph',\n",
       " 'robert',\n",
       " 'david',\n",
       " 'james',\n",
       " 'richard',\n",
       " 'william',\n",
       " 'andrew',\n",
       " 'charles',\n",
       " 'daniel',\n",
       " 'eric',\n",
       " 'stephen',\n",
       " 'mark',\n",
       " 'jonathan',\n",
       " 'anthony',\n",
       " 'steven',\n",
       " 'susan',\n",
       " 'jim',\n",
       " 'christopher',\n",
       " 'edward']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Name of a person\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['john'],set(['john']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel',\n",
       " 'hospital',\n",
       " 'studio',\n",
       " 'gym',\n",
       " 'newspaper',\n",
       " 'bar',\n",
       " 'table',\n",
       " 'team',\n",
       " 'store',\n",
       " 'situation',\n",
       " 'book',\n",
       " 'car',\n",
       " 'settlement',\n",
       " 'moment',\n",
       " 'farm',\n",
       " 'movie',\n",
       " 'song',\n",
       " 'program',\n",
       " 'project',\n",
       " 'scene']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Common Noun - inanimate\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['restaurant'],set(['restaurant']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strong',\n",
       " 'rare',\n",
       " 'wonderful',\n",
       " 'terrible',\n",
       " 'small',\n",
       " 'tough',\n",
       " 'bad',\n",
       " 'simple',\n",
       " 'large',\n",
       " 'strange',\n",
       " 'healthy',\n",
       " 'lovely',\n",
       " 'nice',\n",
       " 'special',\n",
       " 'sharp',\n",
       " 'huge',\n",
       " 'brief',\n",
       " 'tight',\n",
       " 'statement',\n",
       " 'single']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adjective\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['good'],set(['good']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marry',\n",
       " 'shoot',\n",
       " 'hide',\n",
       " 'stop',\n",
       " 'sell',\n",
       " 'kill',\n",
       " 'buy',\n",
       " 'teach',\n",
       " 'treat',\n",
       " 'win',\n",
       " 'grow',\n",
       " 'steal',\n",
       " 'help',\n",
       " 'watch',\n",
       " 'write',\n",
       " 'pass',\n",
       " 'burn',\n",
       " 'produce',\n",
       " 'draw',\n",
       " 'hear']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Verb\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['eat'],set(['eat']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman',\n",
       " 'doctor',\n",
       " 'person',\n",
       " 'boy',\n",
       " 'girl',\n",
       " 'guy',\n",
       " 'kid',\n",
       " 'child',\n",
       " 'patient',\n",
       " 'student',\n",
       " 'song',\n",
       " 'car',\n",
       " 'tree',\n",
       " 'soldier',\n",
       " 'dog',\n",
       " 'giant',\n",
       " 'pitcher',\n",
       " 'reporter',\n",
       " 'restaurant',\n",
       " 'player']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Common Noun - animate\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['man'],set(['man']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'lovely',\n",
       " 'small',\n",
       " 'rare',\n",
       " 'huge',\n",
       " 'strange',\n",
       " 'strong',\n",
       " 'good',\n",
       " 'large',\n",
       " 'brief',\n",
       " 'single',\n",
       " 'giant',\n",
       " 'special',\n",
       " 'brilliant',\n",
       " 'massive',\n",
       " 'statement',\n",
       " 'sharp',\n",
       " 'tiny',\n",
       " 'handsome',\n",
       " 'great']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adjective\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['terrible'],set(['terrible']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Response to Question 3***\n",
    "\n",
    "From the outputs shown above, the cosine distance is able to obtain words which share the same POS tag. Eg. Proper Noun like john produces more proper nouns and adjectives like good produces more adjectives. So, this can be used to identify the POS for various words by using one or more known examples for them. <br/>\n",
    "While it is good at identifying the words which share the same POS tag, there is no definitive ranking on which words are more similar to the given word. Eg. for restaurant, the word kitchen is more similar than hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "In the next several questions, you'll examine similarities in trained word embeddings, instead of raw context counts.\n",
    "\n",
    "See the file `nyt_word2vec.university_cat_dog`, which contains word embedding vectors pretrained by word2vec [1] for three words: “dog”, “cat”, and “university”. You can open the file in a text editor since it’s quite small.\n",
    "\n",
    "Please complete `cossim_dense(v1,v2)` in `distsim.py` to compute and display the cosine similarities between each pair of these words.\n",
    "\n",
    "*Implementation note:*\n",
    "Notice that the inputs of `cossim_dense(v1,v2)` are numpy arrays. If you do not very familiar with the basic operation in numpy, you can find some examples in the basic operation section here:\n",
    "https://docs.scipy.org/doc/numpy-dev/user/quickstart.html\n",
    "\n",
    "If you know how to use Matlab but haven't tried numpy before, the following link should be helpful:\n",
    "https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html\n",
    "\n",
    "[1] Mikolov, Tomas, et al. \"Distributed representations of words and phrases and their compositionality.\" NIPS 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between cat and dog 0.827517295965\n",
      "Cosine similarity between cat and university -0.205394745036\n",
      "Cosine similarity between university and dog -0.190753135501\n",
      "['cat', 'university']\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.university_cat_dog\")\n",
    "print \"Cosine similarity between cat and dog\" ,distsim.cossim_dense(word_to_vec_dict['cat'],word_to_vec_dict['dog'])\n",
    "print \"Cosine similarity between cat and university\" ,distsim.cossim_dense(word_to_vec_dict['cat'],word_to_vec_dict['university'])\n",
    "print \"Cosine similarity between university and dog\" ,distsim.cossim_dense(word_to_vec_dict['university'],word_to_vec_dict['dog'])\n",
    "\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.university_cat_dog\")\n",
    "print distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['dog'], set(['dog']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (25 points)\n",
    "\n",
    "Repeat the process you did in the question 3, but now use dense vector from word2vec. Comment on whether the outputs makes sense. Compare the outputs of using `show_nearest()` on word2vec and the outputs on sparse context vector (so we suggest you to use the same words in question 3). Which method works better on the query words you choose. Please brief explain why one method works better than other in each case.\n",
    "\n",
    "Notice that we use default parameters of word2vec in [gensim](https://radimrehurek.com/gensim/models/word2vec.html) to get word2vec word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import distsim; reload(distsim)\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.4k\")\n",
    "###Provide your answer bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'joseph',\n",
       " 'william',\n",
       " 'edward',\n",
       " 'richard',\n",
       " 'james',\n",
       " 'robert',\n",
       " 'charles',\n",
       " 'donald',\n",
       " 'david',\n",
       " 'thomas',\n",
       " 'patrick',\n",
       " 'peter',\n",
       " 'anthony',\n",
       " 'stephen',\n",
       " 'andrew',\n",
       " 'mark',\n",
       " 'alan',\n",
       " 'jonathan',\n",
       " 'michael']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Name of a person\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['john'],set(['john']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel',\n",
       " 'shop',\n",
       " 'bar',\n",
       " 'mall',\n",
       " 'restaurants',\n",
       " 'store',\n",
       " 'chef',\n",
       " 'factory',\n",
       " 'pizza',\n",
       " 'kitchen',\n",
       " 'menu',\n",
       " 'garden',\n",
       " 'beer',\n",
       " 'breakfast',\n",
       " 'hotels',\n",
       " 'apartment',\n",
       " 'gym',\n",
       " 'starbucks',\n",
       " 'studio',\n",
       " 'lunch']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Common Noun - inanimate\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['restaurant'],set(['restaurant']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'tough',\n",
       " 'nice',\n",
       " 'great',\n",
       " 'happy',\n",
       " 'smart',\n",
       " 'fun',\n",
       " 'healthy',\n",
       " 'lucky',\n",
       " 'positive',\n",
       " 'big',\n",
       " 'hard',\n",
       " 'stupid',\n",
       " 'easy',\n",
       " 'terrible',\n",
       " 'best',\n",
       " 'perfect',\n",
       " 'better',\n",
       " 'really',\n",
       " 'weird']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adjective\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['good'],set(['good']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drink',\n",
       " 'enjoy',\n",
       " 'sleep',\n",
       " 'feed',\n",
       " 'breathe',\n",
       " 'wear',\n",
       " 'forget',\n",
       " 'ate',\n",
       " 'burn',\n",
       " 'get',\n",
       " 'eating',\n",
       " 'treat',\n",
       " 'smell',\n",
       " 'buy',\n",
       " 'listen',\n",
       " 'sit',\n",
       " 'see',\n",
       " 'cook',\n",
       " 'stick',\n",
       " 'hang']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Verb\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['eat'],set(['eat']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman',\n",
       " 'boy',\n",
       " 'girl',\n",
       " 'guy',\n",
       " 'soldier',\n",
       " 'person',\n",
       " 'kid',\n",
       " 'someone',\n",
       " 'dog',\n",
       " 'girlfriend',\n",
       " 'doctor',\n",
       " 'cat',\n",
       " 'driver',\n",
       " 'child',\n",
       " 'friend',\n",
       " 'men',\n",
       " 'hero',\n",
       " 'actor',\n",
       " 'character',\n",
       " 'smile']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Common Noun - animate\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['man'],set(['man']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['horrible',\n",
       " 'sad',\n",
       " 'strange',\n",
       " 'scary',\n",
       " 'shame',\n",
       " 'weird',\n",
       " 'stupid',\n",
       " 'bad',\n",
       " 'ridiculous',\n",
       " 'fantastic',\n",
       " 'worst',\n",
       " 'funny',\n",
       " 'true',\n",
       " 'definitely',\n",
       " 'good',\n",
       " 'wonderful',\n",
       " 'basically',\n",
       " 'serious',\n",
       " 'tough',\n",
       " 'sorry']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adjective\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['terrible'],set(['terrible']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response to question 6:**\n",
    "\n",
    "The word2vec values also produce similar words that might share the same POS tag. Along with that, they also retain a context from the original word. Eg. For restaurant, the most similar words are hotel, shop, bar, chef etc. These are the words which are more associated with restaurant than words like hospital, studio, gym etc. Along with the context, for adjectives, some form of sentiment might also be reflected in the similar words chose. Eg. Good produces great, happy (compared to small and terrible produced by sparse dict) and terrible produces horrible, sad, scary (compared to wonderful and lovely produced by sparse dict). There was no noticable difference for Proper Nouns. So, for this corpus, the word2vec dense representation seems to be providing better results based on the above provided examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (15 points)\n",
    "After you have word embedding, one of interesting things you can do is to perform analogical reasoning tasks. In the following example, we provide the code which can find the closet words to the vector $v_{king}-v_{man}+v_{woman}$ to fill the blank on the question:\n",
    "\n",
    "king : man = ____ : woman\n",
    "\n",
    "Notice that the word2vec is trained in an unsupervised manner; it is impressive that it can apparently do an interesting type of reasoning.  (For a contrary opinion, see [Linzen 2016](http://www.aclweb.org/anthology/W/W16/W16-2503.pdf).)\n",
    "\n",
    "Please come up with another analogical reasoning task (another triple of words), and output the answer using the the same method. Comment on whether the output makes sense. If the output makes sense, explain why we can capture such relation between words using an unsupervised algorithm. Where does the information come from? On the other hand, if the output does not make sense, propose an explanation why the algorithm fails on this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen\n",
      "hospital\n"
     ]
    }
   ],
   "source": [
    "import distsim\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "print distsim.show_nearest(word_to_vec_dict,\n",
    "                     king-man+woman,\n",
    "                     set(['king','man','woman']),\n",
    "                     distsim.cossim_dense)[0]\n",
    "###Provide your answer bellow\n",
    "restaurant = word_to_vec_dict['restaurant']\n",
    "chef = word_to_vec_dict['chef']\n",
    "doctor = word_to_vec_dict['doctor']\n",
    "print distsim.show_nearest(word_to_vec_dict,\n",
    "                     restaurant-chef+doctor,\n",
    "                     set(['restaurant','chef','doctor']),\n",
    "                     distsim.cossim_dense)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your response here:**\n",
    "The reasoning task chosen was restaurant:chef = ____:doctor. As shown above, the correct answer \"hospital\" is chosen.\n",
    "As we are choosing the relationship between a subject and an object, the nature of the relationship is captured by the \"-\" operation (king-man captures \"is a\", restaurant-chef captures \"has employee\" among possible options). When this relationship is applied to another vector, the produced vector is most similar to a subject/object which has that relationship with the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit (up to 5 points)\n",
    "\n",
    "Analyze word similarities with WordNet, and compare and contrast against the distributional similarity results. For a fair comparison, limit yourself to words in the `nytcounts.4k` vocabulary. First, calculate how many of the words are present in WordNet, at least based on what method you’re doing lookups with. (There is an issue that WordNet requires a part-of-speech for lookup, but we don’t have those in our data; you’ll have to devise a solution). \n",
    "\n",
    "Second, for the words you analyzed with distributional similarity above, now do the same with WordNet-based similarity as implemented in NLTK, as described <a href=\"http://www.nltk.org/howto/wordnet.html\">here</a>, or search for “nltk wordnet similarity”. For a fair comparison, do the nearest-similarity ranking among the words in the `nytcounts.4k` vocabulary. You may use `path_similarity`, or any of the other similarity methods (e.g. `res_similarity` for Resnik similarity, which is one of the better ones). Describe what you are doing. Compare and contrast the words you get. Does WordNet give similar or very different results? Why?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit (up to 5 points)\n",
    "\n",
    "Investigate a few of the alternative methods described in [Linzen 2016](http://www.aclweb.org/anthology/W/W16/W16-2503.pdf) on the man/woman/king/queen and your new example.  What does this tell you about the legitimacy of analogical reasoning tasks?  How do you assess Linzen's arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
