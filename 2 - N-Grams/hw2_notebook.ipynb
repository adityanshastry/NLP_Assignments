{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2: N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due on **Friday, Sept 23 (11:59pm)**, submitted electronically.\n",
    "\n",
    "You will submit two files: (1) this jupyter notebook file with answers, and also (2) hw2.py.  (do not include any other files.)\n",
    "\n",
    "We provide a starter version of hw2.py with stub functions that need to be completed.  Much of the code in this notebook calls functions from the hw2.py module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Your Name:** *Aditya Shastry*\n",
    "\n",
    "* **List collaborators:** *Forever Alone*\n",
    "\n",
    "(see our [grading and policies page](http://people.cs.umass.edu/~brenocon/inlp2016/grading.html) for details on our collaboration policy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Toy Example for Testing\n",
    "\n",
    "When implementing algorithms, it's crucial to design test cases to make sure your code works.  The best way to start is to run it on inputs where you know the correct answer in advance, or the range of correct answers.  (If you automate these types of tests, they're called _unit tests_ and are a standard technique in software engineering.)\n",
    "\n",
    "We'll take the approach of having a tiny, synthetic \"toy\" dataset to experiment with.  It's important to run tests on this first before real-world data.  Toy datasets run more quickly.  Also, outputs from real-world data might look good enough so that you miss bugs.\n",
    "\n",
    "Our toy example has a vocabulary of three word types \"A\", \"B\", and special \\*\\*START\\*\\* and \\*\\*END\\*\\* symbols.  We'll calculate some quantities by hand to help verify the correctness of your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a toy corpus that's eight tokens long (including start/end tokens).\n",
    "```\n",
    "  **START** A A A B B B **END**\n",
    "```\n",
    "\n",
    "And here are the bigram counts.\n",
    "\n",
    "|        | wnext = A | wnext = B  |  wnext = \\*\\*END\\*\\*  | \n",
    "|--------|---------------|---|---|\n",
    "| wprev = A |         2          |  1 |  0 |\n",
    "| wprev = B |         0          | 2  |  1 |\n",
    "| wprev = \\*\\*START\\*\\* |     1          | 0  |  0 | \n",
    "\n",
    "\n",
    "And below is the same thing in Python dictionaries.  Evaluate the cell below, since we'll use this data later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_counts_toy={\"A\":3,\"B\":3,\"**START**\":1,\"**END**\":1}\n",
    "bi_counts_toy={\"A\":{ \"A\": 2, \"B\":1 },\"B\": {\"B\":2,\"**END**\":1},\"**START**\":{\"A\":1} }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Conditional Probability\n",
    "\n",
    "For a $k$-gram model (of history size $k-1$), and vocabulary size $V$, we have:\n",
    "\n",
    "$$ P(w_i | w_{i-k+1}..w_{i-1} ) = \\frac{ c(w_{i-k+1}..w_i) + \\alpha }{ c(w_{i-k+1}..w_{i-1}) + \\alpha V }. $$\n",
    "\n",
    "Where $\\alpha$ is the number of pseudocounts for every word type.  In lecture, we usually used $\\alpha=1$. In this homework we'll just use $k=1$ and $\\alpha=0$.\n",
    "\n",
    "We assume always that $w_1=$\\*\\*START\\*\\*, a special symbol denoting the start of a sentence.  A sentence always ends with the special symbol \\*\\*END\\*\\*.  In terms of the generative assumption of the model, the model assume a \\*\\*START\\*\\* symbol exists in the first position, then it generates words one by one.  When it generates a \\*\\*END\\*\\* symbol, the generative process stops.\n",
    "\n",
    "**Question B-1 (10 points):**\n",
    "\n",
    "Please compute the entire conditional probability table for $P(w_{next} | w_{prev1})$ for $w_{prev} \\in \\{A,B,\\text{**}START\\text{**}\\}$ and $w_{next} \\in \\{A,B,\\text{**}END\\text{**}\\}$. Fill in your answers in the table below.  (It might be easier to do this on paper first.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "|        | P(wnext = A &#124;  w1) | P(wnext = B &#124; w1)  |  P(wnext = END &#124; w1)  | \n",
    "|--------|-------------------|--------|--------|\n",
    "| wprev = A |      0.67         |  0.33  |  0     |\n",
    "| wprev = B |      0            |  0.67  |  0.33  |\n",
    "| wprev = START |   1           |  0     |        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Draw samples from unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility code**\n",
    "\n",
    "Please look at `hw2.py`, which contains `weighted_draw_from_dict(prob_dict)`.  You give it a dictionary where they keys are strings, and the values are their probabilities, and it returns a single random sample from that distribution.\n",
    "\n",
    "For example, run the following code a bunch of times.  It randomly returns `'a'` 75% of the time and `'b'` 25% of the time.\n",
    "\n",
    "(The import statement should work if hw2.py is in the same directory as this jupyter notebook file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hw2; reload(hw2)\n",
    "hw2.weighted_draw_from_dict({'a': 0.75, 'b': 0.25})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question C-1 (2 points):**\n",
    "\n",
    "If you drew from the above distribution 10,000 times, what is the expectation of the number of times `'a'` will occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "***ANSWER:***\n",
    "\n",
    "Expected number of occurances for 'a' = P('a') &#42; Total number of repititions = 0.75 &#42; 10000 = **7500**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question C-2 (3 points):**\n",
    "\n",
    "Write a very small bit of test code to confirm `weighted_draw_from_dict` performs as advertised.  Draw from the above distribution 10,000 times and check to see the outcome of `'a'` occurs approximately the number of times it's expected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7491\n"
     ]
    }
   ],
   "source": [
    "import hw2\n",
    "\n",
    "count = 0\n",
    "letter_dict = {'a': 0.75, 'b': 0.25}\n",
    "\n",
    "for i in range(10000):\n",
    "    if hw2.weighted_draw_from_dict(letter_dict) == 'a':\n",
    "        count += 1\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Language model sampling\n",
    "\n",
    "In the following questions, we'll sample from a language model, based on ngram count tables, with a pseudocount of zero.\n",
    "\n",
    "First we'll write `draw_next_word_from_bigram_model` (which samples from $P(w)$) and then `draw_next_word_from_bigram_model` (which samples from $P(w_i | w_{i-1})$).\n",
    "Finally we'll write the `sample_sentence` function to sample a sentence from the bigram model.\n",
    "\n",
    "Throughout, make sure to test the code on the toy corpus: `uni_counts_toy` and `bi_counts_toy` from earlier in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question D-1: Draw from unigram distribution (10 points)**\n",
    "\n",
    "Please implement `draw_next_word_unigram_model` in hw2.py, and ensure the test cases below work correctly.  The starter code always returns a nonsense string, so the test cases should run out of the box, but give bad answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST CODE: run but do not change. Just take a sample.\n",
    "import hw2; reload(hw2)\n",
    "hw2.draw_next_word_unigram_model(uni_counts_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram counts: {'A': 3, 'B': 3, '**END**': 1, '**START**': 1}\n",
      "Random sample counts. Should have same proportions as original counts.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'**END**': 1056, '**START**': 1000, 'A': 2989, 'B': 2955})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST CODE: run but do not change. Take lots of samples.\n",
    "import hw2; reload(hw2)\n",
    "print \"unigram counts:\", uni_counts_toy\n",
    "from collections import Counter\n",
    "print \"Random sample counts. Should have same proportions as original counts.\"\n",
    "Counter([hw2.draw_next_word_unigram_model(uni_counts_toy) for i in range(8000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question D-2: Draw from bigram distribution (15 points)**\n",
    "\n",
    "Please implement `draw_next_word_bigram_model`.  It takes three parameters: the first two are the unigram and bigram count tables, which effectively define the model.  The third parameter is the previous context word.  Make sure both test cases below run with correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AA'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test code: draw once\n",
    "import hw2; reload(hw2)\n",
    "hw2.draw_next_word_bigram_model(uni_counts_toy,bi_counts_toy,\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX A --> Counter({'AA': 648, 'AB': 352})\n",
      "PREFIX B --> Counter({'BB': 670, 'B**END**': 330})\n",
      "PREFIX **START** --> Counter({'**START**A': 1000})\n"
     ]
    }
   ],
   "source": [
    "## Test code: draw many times\n",
    "from collections import Counter\n",
    "for w in ['A','B','**START**']:\n",
    "    manydraws = [hw2.draw_next_word_bigram_model(uni_counts_toy,bi_counts_toy,w) \\\n",
    "                 for i in range(1000)]\n",
    "    sample_counts=Counter(manydraws)\n",
    "    print \"PREFIX %s --> %s\" % (w, sample_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question D-3: Implementing sentence sampling (30 points):**\n",
    "\n",
    "Next, you will write the function `sample_sentence` which generates a new sentence from a given model (and pseudocount value of 0). Here are some considerations:\n",
    "\n",
    "* You should reuse the `next_word_from_bigram_model` function.\n",
    "\n",
    "* You should generate a sentence that starts with \\*\\*START\\*\\* and ends with \\*\\*END\\*\\* token. Other sequences of words have zero probability under the model, so they should never be generated.  To start the function, you just set the first token to be \\*\\*START\\*\\* with probability one. You should keep randomly generating tokens, conditional on the previous word, until you generate the \\*\\*END\\*\\* token.\n",
    "\n",
    "* If your code has a bug and you enter an infinite loop and the \"Stop\" button in jupyter doesn't work, use Ctrl-C on the command line that launched the jupyter notebook.  You'll have to re-run all the cells to load back in the toy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**START**', 'A', 'B', '**END**']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test code -- draw one sample.  Run but do not change.  Run many times to be sure...\n",
    "import hw2; reload(hw2)\n",
    "hw2.sample_sentence(uni_counts_toy, bi_counts_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Data!\n",
    "\n",
    "Now that everything works on a toy model, we'll run on real data based on the movie review dataset from HW1.  We have actually already peformed tokenization, normalization, and n-gram counting for you and are supplying you the unigram and bigram count tables.  Their structure is the same as the toy corpus ngram count dictionaries.  (If you're curious, we used [this script](http://people.cs.umass.edu/~brenocon/inlp2016/hw2/word_count_json.py) with NLTK to do the processing.)\n",
    "\n",
    "First, make sure the `unigram_count_IMDB.json` and `bigram_count_IMDB.json` files are in the current directory and load them with the following code.  Second, make sure you can sample from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory /Users/BatComp/Desktop/UMass/NLP - 585/Assignments/hw2\n",
      "loaded 22279 unigram types\n",
      "loaded 22278 bigram types\n"
     ]
    }
   ],
   "source": [
    "# Loading code\n",
    "import json, os\n",
    "print \"current working directory\", os.getcwd()\n",
    "uni_counts_IMDB = json.load(open('unigram_count_IMDB.json'))\n",
    "print \"loaded %s unigram types\" % len(uni_counts_IMDB)\n",
    "bi_counts_IMDB = json.load(open('bigram_count_IMDB.json'))\n",
    "print \"loaded %s bigram types\" % len(bi_counts_IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Take a sample\n",
    "import hw2; reload(hw2)\n",
    "for i in range(10):\n",
    "    print u' '.join(hw2.sample_sentence(uni_counts_IMDB, bi_counts_IMDB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: How Well do N-Gram Models Capture Grammar?\n",
    "\n",
    "**Question E-1 (20 points)**\n",
    "\n",
    "Sample ten sentences from the IMDB bigram model, then copy and paste them as text into the cell below.  For each, judge whether the sentence is grammatical in English.  How many sentences are grammatical out of 10?  If you had to formulate particular standards for how you define grammaticality, please explain.  (Notice we're talking about grammaticality, like whether the sentence is well-formed, as opposed to the sentence's meaning.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "\n",
    "```\n",
    "The simple rules of grammar to evaluate the sentences:\n",
    "    Subject/Predicate principle\n",
    "    Punctuation marks are not words\n",
    "\n",
    "1) **START** one all around angrily , injecting clever one of the twilight zone does come up , damsel '' i 've \n",
    "never really bad ass . **END**\n",
    "Analysis: \"one all around angrily , injecting clever one of the twilight zone does come up\" - this part alone is a sentence. But \"damsel '' i 've never really bad ass\" is not as \"bad ass\" is not a verb.\n",
    "\n",
    "2) **START** with thigh-high nazi criminal girls ? **END**\n",
    "Analysis: Though highly rediculous, this is a sentence.\n",
    "\n",
    "3) **START** to develop a bit of algiers '' which was one of the very fond of pressures of alice 's stylishly made the flashbacks - apparently directing seems to enough for yourself were laughing at this film that he reveals \n",
    "herself anymore . **END**\n",
    "Analysis: This sentence is very long with improper use of adverbs \"stylishly made the flashbacks\". And, \"apparently directing seems to enough for yourself were laughing at this film that he reveals herself anymore\" has no clear verb and noun and a relation between them\n",
    "\n",
    "4) **START** i was a real deal of my own right through . **END**\n",
    "Analyis: This is a proper sentence\n",
    "\n",
    "5) **START** however , & inspiring because after the series on the open a young pert bottom swings past hosts are \n",
    "truly he has to geraldo rivera 's a naive jerk who do in the 2000 ) nothing really understand how easy . \n",
    "**END**\n",
    "Analysis: The sentence starts off with the correct structure. But loses it at \"are truly he has to geraldo rivera 's\".\n",
    "This is not a sentence.\n",
    "\n",
    "6) **START** ) . **END**\n",
    "Analysis: This is not a sentence\n",
    "\n",
    "7) **START** paradise would be . **END**\n",
    "Analysis: This is a sentence\n",
    "\n",
    "8) **START** at a level of the break the detective martin in order to vietnam '' , which horrifies the creepy . \n",
    "**END**\n",
    "Analysis: This has a noun \" the detective martin\", a verb \"in order to vietnam\"  in proper structure. This is a sentence.\n",
    "\n",
    "9) **START** 9 out that resulted in every moment , it has been , if you laugh for robots in a boiling story it 's abortive remake of the reasoning behind . **END**\n",
    "Analysis: If \"it 's abortive remake of the reasoning behind .\" was a seperate sentence, this would have been a sentence.\n",
    "\n",
    "10) **START** ( that many occasions and the backbone the town people dare not be raving about to anything , scary \n",
    "'' is not for paul f. ryan ( 2004 . **END**\n",
    "Analysis: This has a noun \"the town people\" and a verb \" raving about anything\" with a few adjectives. This is a sentence.\n",
    "\n",
    "5 out of the 10 sentences generated are grammatically correct according to the Subject/Predicate principle.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question E-2 (10 points)**\n",
    "\n",
    "Based on reading these samples, what are the strengths and weaknesses of n-gram language models?  What phenonmena can it model, and what does it get wrong?  When possible, please refer to specific examples in the sentences you just analyzed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "\n",
    "```\n",
    "Strengths: Retains the relationship between commonly occuring words/tokens. This makes it simpler to predict \n",
    "the next word in the sentence. This is usually used in keyboard autosuggest.\n",
    "Weaknesses: As the relationship between only n words are computed, sentences much longer than n lose meaning \n",
    "(as shown in the sentences in E1). Also, if a context has to be maintained for a longer sequence, it becomes \n",
    "much harder for a smaller n. Eg. for n = 3 and phrase \"not in my backyard\", the context \"not\" might be lost.\n",
    "\n",
    "The N-Gram can model a particular genre well. Eg. we can apply 4-Gram modelling to the corpus containing \n",
    "Dr. Seuss's children's stories. This data can be used to generate new stories and some of them may be very \n",
    "accurate and good.\n",
    "But the above model can be used only for children's stories. We cannot use them to generate shakespere, as \n",
    "the vocabulary, the complexity of sentences changes. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
