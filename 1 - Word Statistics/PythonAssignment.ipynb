{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded:  1136\n",
      "This is a complex film that explores the effects of Fordist and Taylorist modes of industrial capitalist production on human relations. There are constant references to assembly line production, where workers are treated as cogs in a machine, overseen by managers wielding clipboards, controlling how much hair the workers leave exposed, and firing workers (Stanley) who meet all criteria (as his supervisor says, are always on time, are hard workers, do good work) but who may in some unspecified fu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os,sys,re,math\n",
    "\n",
    "# This dictionary will hold all the documents.\n",
    "# Keys and values are intended to both be strings.\n",
    "#   Keys: the filename\n",
    "#   Values: the text content of the file\n",
    "\n",
    "fname2content = {}  # {filename: text of file}\n",
    "\n",
    "#-------------------Don't modify the code above-------------------------\n",
    "#-------------------Provide your answer below--------------------------\n",
    "\n",
    "path = 'imdb_pos_sample'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    #to ignore the auto created .DS_Store file, or any file not ending with a .txt\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = path + '/' + filename\n",
    "        fileContents = open(filepath)\n",
    "        fname2content[filename] = fileContents.read()\n",
    "        fileContents.close()\n",
    "\n",
    "#-------------------Provide your answer above---------------------------\n",
    "#-------------------Don't modify the code below------------------------\n",
    "# or only minimally modify it in case your keys have a slightly different format\n",
    "print \"Number of documents loaded: \", len(fname2content)\n",
    "print fname2content[\"17_9.txt\"][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of tokens:  264898\n"
     ]
    }
   ],
   "source": [
    "total_token_num=0\n",
    "\n",
    "#-------------------Don't modify the code above-------------------------\n",
    "#-------------------Provide your answer bellow--------------------------\n",
    "\n",
    "for reviewfile in fname2content:\n",
    "    total_token_num += len(fname2content[reviewfile].split())\n",
    "\n",
    "#-------------------Provide your answer above---------------------------\n",
    "#-------------------Don't modify the code bellow------------------------\n",
    "\n",
    "print \"Total Number of tokens: \", total_token_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive tokenizations\n",
      "['Hello,', 'we', 'are', 'good.']\n",
      "['OK...', \"I'll\", 'go', 'here,', 'ok?']\n",
      "Better tokenizations\n",
      "['Hello', 'we', 'are', 'good']\n",
      "['OK', \"I'll\", 'go', 'here', 'ok']\n"
     ]
    }
   ],
   "source": [
    "## --- keep this code ---\n",
    "examples = [\"Hello, we are good.\",  \"OK... I'll go here, ok?\"]\n",
    "\n",
    "print \"Naive tokenizations\"\n",
    "for example in examples:\n",
    "    print example.split()\n",
    "\n",
    "## --- modify code below ---\n",
    "\n",
    "def better_tokenizer(text):\n",
    "    tokens = re.split(r'\\s*[\\.,\\?:;<>\\/\\(\\)\\\"\\*\\-\\s\\!`]+\\s*', text)\n",
    "    if '' in tokens:\n",
    "        tokens.remove('')\n",
    "    return tokens\n",
    "\n",
    "print \"Better tokenizations\"\n",
    "for example in examples:\n",
    "    print better_tokenizer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  23266\n",
      "Top 10 most common terms:\n",
      "the\n",
      "and\n",
      "a\n",
      "of\n",
      "to\n",
      "is\n",
      "br\n",
      "in\n",
      "that\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "#-------------------Provide your answer below--------------------------\n",
    "import operator\n",
    "word_counts = {}   ## will contain {word: count}\n",
    "\n",
    "for reviewfile in fname2content:\n",
    "    for reviewtoken in better_tokenizer(fname2content[reviewfile]):\n",
    "        if reviewtoken not in word_counts:\n",
    "            word_counts[reviewtoken] = 0\n",
    "        word_counts[reviewtoken] += 1\n",
    "\n",
    "print \"Vocabulary: \", len(word_counts)\n",
    "toptenvocabulary = sorted(word_counts.items(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "print \"Top 10 most common terms:\"\n",
    "for toptenword in toptenvocabulary:\n",
    "    print toptenword[0]\n",
    "\n",
    "#some of the HTML breakpoints like <br> have been retained. was not sure whether to remove them. hence they occur\n",
    "# in the top vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
